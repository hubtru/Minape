{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9589ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, concatenate\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow_addons as tfa\n",
    "import keras_tuner\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b64c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "image_size = 256\n",
    "in_channel_spec = 9\n",
    "in_channel_tool = 3\n",
    "num_classes = 3\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 1\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f4b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "#Convert images to numpy array\n",
    "\n",
    "def read_tools(file_paths, image_size, channels):\n",
    "  images = []\n",
    "  \n",
    "  for file_path in file_paths:\n",
    "    img = cv2.imread(file_path)\n",
    "    res = cv2.resize(img, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    images.append(res)\n",
    "  \n",
    "  images = np.asarray(images, dtype=np.float32)\n",
    "  \n",
    "  # normalize\n",
    "  images = images / np.max(images)\n",
    "  \n",
    "  # reshape to match Keras expectaions\n",
    "  images = images.reshape(images.shape[0], image_size, image_size, channels)\n",
    "\n",
    "  return images\n",
    "\n",
    "def read_specs(file_paths_x, file_paths_y, file_paths_z, image_size, channels):\n",
    "  images = []\n",
    "  \n",
    "  for i in range(file_paths_x.size):\n",
    "    img_x = cv2.imread(file_paths_x[i])\n",
    "    res_x = cv2.resize(img_x, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    images.append(res_x)\n",
    "    img_y = cv2.imread(file_paths_y[i])\n",
    "    res_y = cv2.resize(img_y, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    images.append(res_y)\n",
    "    img_z = cv2.imread(file_paths_z[i])\n",
    "    res_z = cv2.resize(img_z, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    images.append(res_z)\n",
    "  \n",
    "  images = np.asarray(images, dtype=np.float32)\n",
    "  images = images / np.max(images)\n",
    "  images = images.reshape(file_paths_x.shape[0], image_size, image_size, channels)\n",
    "\n",
    "  return images\n",
    "\n",
    "\n",
    "#Patch dataset\n",
    "\n",
    "def generate_datasets(images, labels, is_train=False):\n",
    "    dataset = images\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    if is_train:\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (data_augmentation(x), y), num_parallel_calls=auto\n",
    "            \n",
    "        )\n",
    "    return dataset.prefetch(auto)\n",
    "\n",
    "\n",
    "#Model creation methods\n",
    "#This method deletes last classification layers from the network, and adds concatenation layer with gru layer\n",
    "#and new classification layer.\n",
    "def multimodal_conv_build(model_tool, model_spec):\n",
    "    inputs1 = model_tool.input\n",
    "    inputs1._name = \"input_tool\"\n",
    "    inputs2 = model_spec.input\n",
    "    inputs2._name = \"input_spec\"\n",
    "    truncated_model_tool = k.Model(inputs = model_tool.input, outputs = model_tool.layers[-2].output)\n",
    "    truncated_model_spec = k.Model(inputs = model_spec.input, outputs = model_spec.layers[-2].output)\n",
    "    mergedOut = k.layers.Concatenate()([truncated_model_tool.output, truncated_model_spec.output])\n",
    "    reshape = layers.Reshape((1, 1024))(mergedOut)\n",
    "    gru = layers.GRU(256, dropout=0.1)(reshape)\n",
    "    output = layers.Dense(num_classes, activation=\"softmax\", name=\"output_mult\")(gru)\n",
    "    return k.Model(inputs=[inputs1 ,inputs2], outputs=output)\n",
    "\n",
    "\n",
    "#Run experiment\n",
    "\n",
    "def launch_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = k.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "        dataset_train,\n",
    "        validation_data=dataset_val,\n",
    "        epochs=num_epochs,\n",
    "        shuffle=False,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy = model.evaluate(dataset_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ac9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset acquisition\n",
    "train_df = pd.read_csv('../Data/Labels/train.csv', index_col=0)\n",
    "test_df = pd.read_csv('../Data/Labels/test.csv', index_col=0)\n",
    "val_df = pd.read_csv('../Data/Labels/val.csv', index_col=0)\n",
    "\n",
    "train_df['tool'] = train_df.index.map(lambda id: f'../Data/Datasets/tool/{id}.jpg')\n",
    "test_df['tool'] = test_df.index.map(lambda id: f'../Data/Datasets/tool/{id}.jpg')\n",
    "val_df['tool'] = val_df.index.map(lambda id: f'../Data/Datasets/tool/{id}.jpg')\n",
    "\n",
    "train_df['spec_x'] = train_df.index.map(lambda id: f'../Data/Datasets/specX/{id}.png')\n",
    "test_df['spec_x'] = test_df.index.map(lambda id: f'../Data/Datasets/specX/{id}.png')\n",
    "val_df['spec_x'] = val_df.index.map(lambda id: f'../Data/Datasets/specX/{id}.png')\n",
    "\n",
    "train_df['spec_y'] = train_df.index.map(lambda id: f'../Data/Datasets/specY/{id}.png')\n",
    "test_df['spec_y'] = test_df.index.map(lambda id: f'../Data/Datasets/specY/{id}.png')\n",
    "val_df['spec_y'] = val_df.index.map(lambda id: f'../Data/Datasets/specY/{id}.png')\n",
    "\n",
    "train_df['spec_z'] = train_df.index.map(lambda id: f'../Data/Datasets/specZ/{id}.png')\n",
    "test_df['spec_z'] = test_df.index.map(lambda id: f'../Data/Datasets/specZ/{id}.png')\n",
    "val_df['spec_z'] = val_df.index.map(lambda id: f'../Data/Datasets/specZ/{id}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3019d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read tool images and cpectrograms, convert them to NumPy array\n",
    "x_train_tool = read_tools(train_df.tool.values, image_size, in_channel_tool)\n",
    "x_test_tool = read_tools(test_df.tool.values, image_size, in_channel_tool)\n",
    "x_val_tool = read_tools(val_df.tool.values, image_size, in_channel_tool)\n",
    "x_train_spec = read_specs(train_df.spec_x.values,train_df.spec_y.values,train_df.spec_z.values, image_size, in_channel_spec)\n",
    "x_test_spec = read_specs(test_df.spec_x.values,test_df.spec_y.values,test_df.spec_z.values, image_size, in_channel_spec)\n",
    "x_val_spec = read_specs(val_df.spec_x.values,val_df.spec_y.values,val_df.spec_z.values, image_size, in_channel_spec)\n",
    "\n",
    "#Bring the labels to an acceptable form\n",
    "labels_train = train_df.tool_label.values - 1\n",
    "labels_test = test_df.tool_label.values - 1\n",
    "labels_val = val_df.tool_label.values - 1\n",
    "\n",
    "labels_train = tf.keras.utils.to_categorical(\n",
    "    labels_train, num_classes, dtype='float32')\n",
    "labels_test = tf.keras.utils.to_categorical(\n",
    "    labels_test, num_classes, dtype='float32')\n",
    "labels_val = tf.keras.utils.to_categorical(\n",
    "    labels_val, num_classes, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f527d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tensorflow datasets objects and add patch embedding to train dataset\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(({'input_2_tool': x_train_tool, 'input_2_spec': x_train_spec}, labels_train))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices(({'input_2_tool': x_test_tool, 'input_2_spec': x_test_spec}, labels_test))\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices(({'input_2_tool': x_val_tool, 'input_2_spec': x_val_spec}, labels_val))\n",
    "\n",
    "auto = tf.data.AUTOTUNE\n",
    "inputs1 = k.Input((image_size, image_size, in_channel_tool))\n",
    "inputs2 = k.Input((image_size, image_size, in_channel_spec))\n",
    "tool_crop = k.layers.RandomCrop(image_size, image_size)(inputs1)\n",
    "spec_crop = k.layers.RandomCrop(image_size, image_size)(inputs2)\n",
    "tool_crop = k.layers.RandomFlip(\"horizontal\")(tool_crop)\n",
    "spec_crop = k.layers.RandomFlip(\"horizontal\")(spec_crop)\n",
    "\n",
    "data_augmentation = k.Model(\n",
    "    inputs={'input_2_tool': inputs1, 'input_2_spec': inputs2},\n",
    "    outputs={'input_2_tool':tool_crop, 'input_2_spec':spec_crop},\n",
    ")\n",
    "\n",
    "dataset_train = generate_datasets(dataset_train, labels_train, is_train=True)\n",
    "dataset_val = generate_datasets(dataset_val, labels_val)\n",
    "dataset_test = generate_datasets(dataset_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a78e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load inimodal networks and freese them\n",
    "model_tool = k.models.load_model(\n",
    "    \"../models/tool_aug_tool_opt.h5\", compile=False)\n",
    "model_spec = k.models.load_model(\n",
    "    \"../models/spec_aug_tool_opt.h5\", compile=False)\n",
    "\n",
    "model_spec.trainable = False\n",
    "model_tool.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename layers to divide networks\n",
    "for layer in model_tool.layers:\n",
    "    layer._name = layer.name + str('_tool')\n",
    "for layer in model_spec.layers:\n",
    "    layer._name = layer.name + str('_spec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build multimodal network\n",
    "multimodal_conv = multimodal_conv_build(model_tool, model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c643fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show summary\n",
    "multimodal_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run training\n",
    "history, model = launch_experiment(multimodal_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92efdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot accuracy history\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d22c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_score = model.predict(dataset_test)\n",
    "y_test = labels_test\n",
    "\n",
    "n_classes = 3\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "y_classes = np.argmax(y_score, axis=1)\n",
    "labels_test_f1=np.argmax(labels_test, axis=1)\n",
    "print(metrics.confusion_matrix(labels_test_f1, y_classes))\n",
    "print(classification_report(labels_test_f1, y_classes))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels_test_f1, y_classes, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300108ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
