{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49386885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, concatenate\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow_addons as tfa\n",
    "import keras_tuner\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8832bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "image_size = 256\n",
    "in_channel_tool = 3\n",
    "num_classes = 3\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 40\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e3c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "#Multimodal implementation of Trockman, A., & Kolter, J. Z. (2022). Patches are all you need?.\n",
    "#https://github.com/locuslab/convmixer\n",
    "#Convert images to numpy array\n",
    "\n",
    "def read_tools(file_paths, image_size, channels):\n",
    "  images = []\n",
    "  \n",
    "  for file_path in file_paths:\n",
    "    img = cv2.imread(file_path)\n",
    "    res = cv2.resize(img, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    images.append(res)\n",
    "  \n",
    "  images = np.asarray(images, dtype=np.float32)\n",
    "  \n",
    "  # normalize\n",
    "  images = images / np.max(images)\n",
    "  \n",
    "  # reshape to match Keras expectaions\n",
    "  images = images.reshape(images.shape[0], image_size, image_size, channels)\n",
    "\n",
    "  return images\n",
    "\n",
    "#Patch dataset\n",
    "\n",
    "def generate_datasets(images, is_train=False):\n",
    "    dataset = images\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(batch_size * 10)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    if is_train:\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (data_augmentation(x), y), num_parallel_calls=auto\n",
    "        )\n",
    "    return dataset.prefetch(auto)\n",
    "\n",
    "#Model creation methods\n",
    "\n",
    "def activation_module(x):\n",
    "    x = layers.Activation(\"gelu\")(x)\n",
    "    return layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "def base_module(x, filters, patch_size):\n",
    "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
    "    return activation_module(x)\n",
    "\n",
    "\n",
    "def multi_mixer_module(x, filters, kernel_size):\n",
    "    # Depthwise convolution.\n",
    "    x0 = x\n",
    "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
    "    x = layers.Add()([activation_module(x), x0])  # Residual.\n",
    "\n",
    "    # Pointwise convolution.\n",
    "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
    "    x = activation_module(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_multi_mixer(hp):\n",
    "    \n",
    "    filters=hp.Int(\"filters\", min_value=128, max_value=512, step=128)\n",
    "    depth=hp.Int(\"depth\", min_value=4, max_value=8, step=4)\n",
    "    kernel_size=hp.Int(\"kernel_size\", min_value=3, max_value=9, step=1)\n",
    "    patch_size=hp.Int(\"patch_size\", min_value=4, max_value=32, step=4)\n",
    "    \n",
    "    inputs = k.Input((image_size, image_size, in_channel_tool))\n",
    "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
    "\n",
    "    # Extract patch embeddings.\n",
    "    x = base_module(x, filters, patch_size)\n",
    "\n",
    "    # Multi_mixer modul.\n",
    "    for _ in range(depth):\n",
    "        x = multi_mixer_module(x, filters, kernel_size)\n",
    "\n",
    "    # Classification block.\n",
    "    x = layers.GlobalAvgPool2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = k.Model(inputs, outputs)\n",
    "    \n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "#Run experiment\n",
    "\n",
    "def launch_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = k.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        new_train_dataset,\n",
    "        validation_data=new_val_dataset,\n",
    "        epochs=num_epochs,\n",
    "        shuffle=True,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy = model.evaluate(new_test_dataset)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset acquisition\n",
    "train_df = pd.read_csv('../Data/Labels/train.csv', index_col=0)\n",
    "test_df = pd.read_csv('../Data/Labels/test.csv', index_col=0)\n",
    "val_df = pd.read_csv('../Data/Labels/test.csv', index_col=0)\n",
    "\n",
    "train_df['tool'] = train_df.index.map(lambda id: f'../Data/Datasets/tool/{id}.jpg')\n",
    "test_df['tool'] = test_df.index.map(lambda id: f'../Data/Datasets/tool/{id}.jpg')\n",
    "val_df['tool'] = val_df.index.map(lambda id: f'../Data/Datasets/tool/{id}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec997d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot dataset distribution\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.displot(train_df['tool_label'])\n",
    "plt.title('Label Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read tool images and convert them to NumPy array\n",
    "x_train_tool = read_tools(train_df.tool.values, image_size, in_channel_tool)\n",
    "x_test_tool = read_tools(test_df.tool.values, image_size, in_channel_tool)\n",
    "x_val_tool = read_tools(val_df.tool.values, image_size, in_channel_tool)\n",
    "#Bring the labels to an acceptable form\n",
    "labels_train = train_df.tool_label.values - 1\n",
    "labels_test = test_df.tool_label.values - 1\n",
    "labels_val = val_df.tool_label.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babda7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tensorflow datasets objects and add patch embedding to train dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_tool, labels_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_tool, labels_test))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val_tool, labels_val))\n",
    "train_dataset = train_dataset.shuffle(x_train_tool.shape[0], seed=777)\n",
    "\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "data_augmentation = k.Sequential(\n",
    "    [layers.RandomCrop(image_size, image_size), k.layers.RandomFlip(\"horizontal\"),],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "\n",
    "new_train_dataset = generate_datasets(train_dataset, is_train=True)\n",
    "new_val_dataset = generate_datasets(val_dataset)\n",
    "new_test_dataset = generate_datasets(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9050892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi_mixer model architecture optimization\n",
    "hp = keras_tuner.HyperParameters()\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=load_multi_mixer,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    seed=None,\n",
    "    hyperparameters=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    overwrite=True,\n",
    "    project_name=\"tool_opt\"\n",
    ")\n",
    "\n",
    "history_opt = tuner.search(\n",
    "        new_train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        shuffle=True,\n",
    "        validation_data=new_val_dataset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization summary #1\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86817767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization summary #2\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the best model based on architecture optimization\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.build(input_shape=(image_size, image_size, in_channel_tool))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d08b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "model = load_multi_mixer(best_hps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0524bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train optimized architecture\n",
    "history, conv_mixer_model = launch_experiment(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "conv_mixer_model.save(\"../models/tool_aug_tool_opt.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aae39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot accuracy history\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12be026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss history\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc74d4a1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
