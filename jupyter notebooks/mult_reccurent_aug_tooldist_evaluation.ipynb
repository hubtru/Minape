{"cells":[{"cell_type":"code","source":["# clone minape repository, refresh folder to see the minape repository\n","!git clone https://github.com/hubtru/Minape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eu_2Oo5dWqIX","outputId":"9c9db0af-f4c0-4d2c-cd0c-cb2d2b18b9a5"},"id":"Eu_2Oo5dWqIX","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Minape'...\n","remote: Enumerating objects: 131, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 131 (delta 0), reused 3 (delta 0), pack-reused 128\u001b[K\n","Receiving objects: 100% (131/131), 47.82 MiB | 23.21 MiB/s, done.\n","Resolving deltas: 100% (5/5), done.\n"]}]},{"cell_type":"code","source":["# install tensorflow-addons\n","!pip install --upgrade keras==2.15.0\n","!pip install --upgrade tensorflow==2.15.0.post1\n","!pip install --upgrade scipy==1.11.4\n","!pip install tensorflow-addons==0.21.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w_2g9qq3PxK2","outputId":"bf9bf79c-e28d-4c58-abaa-290087b6629a"},"id":"w_2g9qq3PxK2","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/611.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m501.8/611.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"]}]},{"cell_type":"code","execution_count":null,"id":"73ea57b4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73ea57b4","outputId":"3b96d4ee-043c-4bc0-c5fa-ebd03541563f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","import cv2\n","import os\n","\n","import tensorflow as tf\n","from tensorflow import keras as k\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.utils import array_to_img\n","from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, concatenate\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","import tensorflow_addons as tfa"]},{"cell_type":"code","execution_count":null,"id":"c8690684","metadata":{"id":"c8690684"},"outputs":[],"source":["#Variables\n","image_size = 256\n","in_channel_spec = 9\n","in_channel_tool = 3\n","num_classes = 3\n","batch_size = 1"]},{"cell_type":"code","execution_count":null,"id":"1f0b5ec1","metadata":{"id":"1f0b5ec1"},"outputs":[],"source":["#Functions\n","\n","#Convert images to numpy array\n","\n","def read_tools(file_paths, image_size, channels):\n","  images = []\n","\n","  for file_path in file_paths:\n","    img = cv2.imread(file_path)\n","    res = cv2.resize(img, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n","    images.append(res)\n","\n","  images = np.asarray(images, dtype=np.float32)\n","\n","  # normalize\n","  images = images / np.max(images)\n","\n","  # reshape to match Keras expectaions\n","  images = images.reshape(images.shape[0], image_size, image_size, channels)\n","\n","  return images\n","\n","def read_specs(file_paths_x, file_paths_y, file_paths_z, image_size, channels):\n","  images = []\n","\n","  for i in range(file_paths_x.size):\n","    img_x = cv2.imread(file_paths_x[i])\n","    res_x = cv2.resize(img_x, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n","    images.append(res_x)\n","    img_y = cv2.imread(file_paths_y[i])\n","    res_y = cv2.resize(img_y, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n","    images.append(res_y)\n","    img_z = cv2.imread(file_paths_z[i])\n","    res_z = cv2.resize(img_z, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n","    images.append(res_z)\n","\n","  images = np.asarray(images, dtype=np.float32)\n","  images = images / np.max(images)\n","  images = images.reshape(file_paths_x.shape[0], image_size, image_size, channels)\n","\n","  return images\n","\n","\n","#Patch dataset\n","\n","def generate_datasets(images, labels, is_train=False):\n","    dataset = images\n","    dataset = dataset.batch(batch_size)\n","    if is_train:\n","        dataset = dataset.map(\n","            lambda x, y: (data_augmentation(x), y), num_parallel_calls=auto\n","\n","        )\n","    return dataset.prefetch(auto)"]},{"cell_type":"code","execution_count":null,"id":"c560bb86","metadata":{"id":"c560bb86"},"outputs":[],"source":["#Dataset acquisition\n","test_path = '/content/Minape/Data/labels_original/random_distribution/test.csv'\n","test_df = pd.read_csv(test_path, index_col=0)\n","\n","test_data_path = '/content/Minape/Data/dataset_original'\n","test_df['tool'] = test_df.index.map(lambda id: f'{test_data_path}/tool/{id}.jpg')\n","test_df['spec_x'] = test_df.index.map(lambda id: f'{test_data_path}/specX/{id}.png')\n","test_df['spec_y'] = test_df.index.map(lambda id: f'{test_data_path}/specY/{id}.png')\n","test_df['spec_z'] = test_df.index.map(lambda id: f'{test_data_path}/specZ/{id}.png')\n","\n","#Read tool images and spectrograms and convert them to NumPy array\n","x_test_tool = read_tools(test_df.tool.values, image_size, in_channel_tool)\n","x_test_spec = read_specs(test_df.spec_x.values,test_df.spec_y.values,test_df.spec_z.values, image_size, in_channel_spec)"]},{"cell_type":"code","execution_count":null,"id":"a1571ff4","metadata":{"id":"a1571ff4"},"outputs":[],"source":["#Bring the labels to an acceptable form\n","labels_test = test_df.tool_label.values - 1\n","\n","labels_test = tf.keras.utils.to_categorical(\n","    labels_test, num_classes, dtype='float32')\n","\n","#Create tensorflow datasets objects and add patch embedding to train dataset\n","dataset_test = tf.data.Dataset.from_tensor_slices(({'input_2_tool': x_test_tool, 'input_2_spec': x_test_spec}, labels_test))\n","\n","auto = tf.data.AUTOTUNE\n","inputs1 = k.Input((image_size, image_size, in_channel_tool))\n","inputs2 = k.Input((image_size, image_size, in_channel_spec))\n","tool_crop = k.layers.RandomCrop(image_size, image_size)(inputs1)\n","spec_crop = k.layers.RandomCrop(image_size, image_size)(inputs2)\n","tool_crop = k.layers.RandomFlip(\"horizontal\")(tool_crop)\n","spec_crop = k.layers.RandomFlip(\"horizontal\")(spec_crop)\n","\n","data_augmentation = k.Model(\n","    inputs={'input_2_tool': inputs1, 'input_2_spec': inputs2},\n","    outputs={'input_2_tool':tool_crop, 'input_2_spec':spec_crop},\n",")\n","\n","dataset_test = generate_datasets(dataset_test, labels_test)"]},{"cell_type":"code","execution_count":null,"id":"104aaf9f","metadata":{"id":"104aaf9f"},"outputs":[],"source":["#Load multimodal network\n","model_path = '/content/Minape/models'\n","model = k.models.load_model(f\"{model_path}/multimodal_aug_tool.h5\", compile=True)"]},{"cell_type":"code","execution_count":null,"id":"9e05e00b","metadata":{"id":"9e05e00b","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c928e519-b8e8-4c55-d236-a09cb156c10a"},"outputs":[{"output_type":"stream","name":"stdout","text":["3/3 [==============================] - 2s 104ms/step - loss: 0.0109 - accuracy: 1.0000\n","[0.01085010077804327, 1.0]\n"]}],"source":["#Evaluate multimodal network\n","result_eval = model.evaluate(dataset_test)\n","print(result_eval)"]},{"cell_type":"code","execution_count":null,"id":"87d04ca4","metadata":{"id":"87d04ca4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a2c9cfab-4ce9-46eb-8397-e6fd5208bc15"},"outputs":[{"output_type":"stream","name":"stdout","text":["3/3 [==============================] - 1s 61ms/step\n","[0 1 2]\n"]}],"source":["#Classify test datset\n","result_predict = model.predict(dataset_test)\n","result_predict = np.argmax(result_predict, axis=1)\n","print(result_predict)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}