{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, concatenate\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8690684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "image_size = 256\n",
    "in_channel_spec = 9\n",
    "in_channel_tool = 3\n",
    "num_classes = 3\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "#Convert images to numpy array\n",
    "\n",
    "def read_tools(file_paths, image_size, channels):\n",
    "  images = []\n",
    "  \n",
    "  for file_path in file_paths:\n",
    "    img = cv2.imread(file_path)\n",
    "    res = cv2.resize(img, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    images.append(res)\n",
    "  \n",
    "  images = np.asarray(images, dtype=np.float32)\n",
    "  \n",
    "  # normalize\n",
    "  images = images / np.max(images)\n",
    "  \n",
    "  # reshape to match Keras expectaions\n",
    "  images = images.reshape(images.shape[0], image_size, image_size, channels)\n",
    "\n",
    "  return images\n",
    "\n",
    "def read_specs(file_paths_x, file_paths_y, file_paths_z, image_size, channels):\n",
    "  images = []\n",
    "  \n",
    "  for i in range(file_paths_x.size):\n",
    "    img_x = cv2.imread(file_paths_x[i])\n",
    "    res_x = cv2.resize(img_x, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    images.append(res_x)\n",
    "    img_y = cv2.imread(file_paths_y[i])\n",
    "    res_y = cv2.resize(img_y, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    images.append(res_y)\n",
    "    img_z = cv2.imread(file_paths_z[i])\n",
    "    res_z = cv2.resize(img_z, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "    images.append(res_z)\n",
    "  \n",
    "  images = np.asarray(images, dtype=np.float32)\n",
    "  images = images / np.max(images)\n",
    "  images = images.reshape(file_paths_x.shape[0], image_size, image_size, channels)\n",
    "\n",
    "  return images\n",
    "\n",
    "\n",
    "#Patch dataset\n",
    "\n",
    "def generate_datasets(images, labels, is_train=False):\n",
    "    dataset = images\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    if is_train:\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (data_augmentation(x), y), num_parallel_calls=auto\n",
    "            \n",
    "        )\n",
    "    return dataset.prefetch(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset acquisition\n",
    "test_df = pd.read_csv('../Data/Labels/test.csv', index_col=0)\n",
    "\n",
    "test_df['tool'] = test_df.index.map(lambda id: f'../Data/Datasets/tool/{id}.jpg')\n",
    "test_df['spec_x'] = test_df.index.map(lambda id: f'../Data/Datasets/specX/{id}.png')\n",
    "test_df['spec_y'] = test_df.index.map(lambda id: f'../Data/Datasets/specY/{id}.png')\n",
    "test_df['spec_z'] = test_df.index.map(lambda id: f'../Data/Datasets/specZ/{id}.png')\n",
    "\n",
    "#Read tool images and spectrograms and convert them to NumPy array\n",
    "x_test_tool = read_tools(test_df.tool.values, image_size, in_channel_tool)\n",
    "x_test_spec = read_specs(test_df.spec_x.values,test_df.spec_y.values,test_df.spec_z.values, image_size, in_channel_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1571ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring the labels to an acceptable form\n",
    "labels_test = test_df.tool_label.values - 1\n",
    "\n",
    "labels_test = tf.keras.utils.to_categorical(\n",
    "    labels_test, num_classes, dtype='float32')\n",
    "\n",
    "#Create tensorflow datasets objects and add patch embedding to train dataset\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices(({'input_2_tool': x_test_tool, 'input_2_spec': x_test_spec}, labels_test))\n",
    "\n",
    "auto = tf.data.AUTOTUNE\n",
    "inputs1 = k.Input((image_size, image_size, in_channel_tool))\n",
    "inputs2 = k.Input((image_size, image_size, in_channel_spec))\n",
    "tool_crop = k.layers.RandomCrop(image_size, image_size)(inputs1)\n",
    "spec_crop = k.layers.RandomCrop(image_size, image_size)(inputs2)\n",
    "tool_crop = k.layers.RandomFlip(\"horizontal\")(tool_crop)\n",
    "spec_crop = k.layers.RandomFlip(\"horizontal\")(spec_crop)\n",
    "\n",
    "data_augmentation = k.Model(\n",
    "    inputs={'input_2_tool': inputs1, 'input_2_spec': inputs2},\n",
    "    outputs={'input_2_tool':tool_crop, 'input_2_spec':spec_crop},\n",
    ")\n",
    "\n",
    "dataset_test = generate_datasets(dataset_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104aaf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load multimodal network\n",
    "model = k.models.load_model(\n",
    "    \"../models/multimodal_aug_tool.h5\", compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate multimodal network\n",
    "result_eval = model.evaluate(dataset_test)\n",
    "print(result_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d04ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify test datset\n",
    "result_predict = model.predict(dataset_test)\n",
    "result_predict = np.argmax(result_predict, axis=1)\n",
    "print(result_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
